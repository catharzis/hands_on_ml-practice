{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Модель способна выполнять:\n","\n","\n","1.   Линейную классификацию\n","2.   Нелинейную классификацию\n","3. Регрессию\n","4. Выявление выбросов\n","\n","Методы SVM особенно хорошо подходят для классификации сложных, но небольших или средних наборов данных.\n","\n","\n"],"metadata":{"id":"oPnLWj3y5ZYZ"}},{"cell_type":"markdown","source":["# Линейная классификация SVM"],"metadata":{"id":"dF7QVCUu6J8m"}},{"cell_type":"markdown","source":["### Классификация с широким зазором"],"metadata":{"id":"qssGgHm2Ua5o"}},{"cell_type":"markdown","source":["Граница решений классификатора SVM представляет собой линию, находящиеюся **максимально возможно далеко** (как можно более широкой) от ближайших обучающих образцов. Такие образцы называются – опорные вектора"],"metadata":{"id":"HIDEwU-XUe86"}},{"cell_type":"markdown","source":["Алгоритм чувствителен к масштабам признаков. Поэтому в предорбработке нужно использовать `StandartScaler`"],"metadata":{"id":"3cf9Bc_SVf07"}},{"cell_type":"markdown","source":["## Классификация с жестким и мягким зазором"],"metadata":{"id":"09JgBCQh6sle"}},{"cell_type":"markdown","source":["**Жесткий зазор** определяет что все образцы находятся вне полосы.\n","\n","**Мягкий зазор** позволяет нарушать границу, но с ограничением количества нарушений."],"metadata":{"id":"Ouq0ziI5V-zg"}},{"cell_type":"markdown","source":["Проблемы жесткого зазора:\n","\n","1. Невозможность разлеить линейно несепарабельные наборы (если присутствуют выбросы)\n","2. Если наборы сепарабельны, но присутствует один выброс, который близок к \"другому классу\" экземпляров, то такая модель не будет хорошо обобщаться"],"metadata":{"id":"Tbv_Rl5HXMgS"}},{"cell_type":"markdown","source":["В классах SVM библиотеки sklearn возможно управлять балансом \"ширина полосы/ количество нарушений\" гиперпараметром \"C\""],"metadata":{"id":"bHEr8Lc9WvFR"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn import datasets\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import LinearSVC"],"metadata":{"id":"odDjNrhSYAhb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["iris = datasets.load_iris()"],"metadata":{"id":"uyNLNnidYd2z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = iris[\"data\"][:, (2, 3)] # длина и ширина лепестка\n","y = (iris[\"target\"] == 2).astype(np.float64) # ирис вингриский"],"metadata":{"id":"leijYY7iaF1K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_clf = Pipeline([\n","                (\"scaler\", StandardScaler()),\n","                (\"linear_svc\", LinearSVC(C=1, loss=\"hinge\"))])"],"metadata":{"id":"OqqA0qTRafht"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_clf.fit(X, y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LlgO-nctbH-n","executionInfo":{"status":"ok","timestamp":1641389311943,"user_tz":-180,"elapsed":7,"user":{"displayName":"Mark Apiezon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyGsSipbrttT9pVeCINkKIDu1XY1NIVGNEPe6c=s64","userId":"11353121438293927929"}},"outputId":"e1119a92-1128-4787-cd35-5b3b4deedaa7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('scaler', StandardScaler()),\n","                ('linear_svc', LinearSVC(C=1, loss='hinge'))])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["svm_clf.predict([[5.5, 1.7]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7I1WBCpFbWNR","executionInfo":{"status":"ok","timestamp":1641389369362,"user_tz":-180,"elapsed":296,"user":{"displayName":"Mark Apiezon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyGsSipbrttT9pVeCINkKIDu1XY1NIVGNEPe6c=s64","userId":"11353121438293927929"}},"outputId":"2099ea6e-063a-4359-e04a-ec86bac45a98"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1.])"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["SVM не выдает выероятности для каждого класса"],"metadata":{"id":"weWyVcGgblVq"}},{"cell_type":"markdown","source":["# Нелинейная классификация SVM"],"metadata":{"id":"H36scyQv6OWH"}},{"cell_type":"markdown","source":["Если наборы данных далеки от линейно сепарабельных, то пользуются **нелинейной классификацияей**"],"metadata":{"id":"ueXPcMJXDYqX"}},{"cell_type":"markdown","source":["Как обрабатывать нелинейные нвборы?\n","\n","1. Добавить дополнительные полиноминальные признаки"],"metadata":{"id":"RZh_z3-CDmRc"}},{"cell_type":"markdown","source":["## Добавление полиноминальных признаков"],"metadata":{"id":"qxry0jwrD3h_"}},{"cell_type":"code","source":["from sklearn.datasets import make_moons\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import LinearSVC\n","import matplotlib.pyplot as plt\n","\n","polynomial_svm_clf = Pipeline([\n","        (\"poly_features\", PolynomialFeatures(degree=3)),\n","        (\"scaler\", StandardScaler()),\n","        (\"svm_clf\", LinearSVC(C=10, loss=\"hinge\", random_state=42))\n","    ])\n","\n","polynomial_svm_clf.fit(X, y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PWEvOJ7BEA_i","executionInfo":{"status":"ok","timestamp":1641467729485,"user_tz":-180,"elapsed":376,"user":{"displayName":"Mark Apiezon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyGsSipbrttT9pVeCINkKIDu1XY1NIVGNEPe6c=s64","userId":"11353121438293927929"}},"outputId":"8d8ad522-abd4-4681-d890-a78cd4969c4c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('poly_features', PolynomialFeatures(degree=3)),\n","                ('scaler', StandardScaler()),\n","                ('svm_clf', LinearSVC(C=10, loss='hinge', random_state=42))])"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["## Полиноминальное ядро (ядерный трюк)"],"metadata":{"id":"racWbY8_7L-P"}},{"cell_type":"markdown","source":["При низкой полиноминальной степени ПЯ не способно справляться с очень сложными наборами данных, а при высокой оно создает большое количество признаков, делая модель медленной."],"metadata":{"id":"NWI9YXHgISKH"}},{"cell_type":"code","source":["from sklearn.svm import SVC\n","\n","poly_kernel_svm_clf = Pipeline([\n","        (\"scaler\", StandardScaler()),\n","        (\"svm_clf\", SVC(kernel=\"poly\", degree=3, coef0=1, C=5))\n","    ])\n","\n","'''полиноминальное ядро 3 степени, coef0 – насколько сильно полиномы высокой \n","степени влияют на модель в сравнении с полиномами низкой'''\n","poly_kernel_svm_clf.fit(X, y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LL0LcU0KIyna","executionInfo":{"status":"ok","timestamp":1641468557687,"user_tz":-180,"elapsed":725,"user":{"displayName":"Mark Apiezon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyGsSipbrttT9pVeCINkKIDu1XY1NIVGNEPe6c=s64","userId":"11353121438293927929"}},"outputId":"1a93bc5b-d85f-441b-9450-a1c8f7a905b0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('scaler', StandardScaler()),\n","                ('svm_clf', SVC(C=5, coef0=1, kernel='poly'))])"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["poly_kernel_svc_clf.fit(X, y)"],"metadata":{"id":"ZVzI-l40Jb9V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Добавление признаков близости"],"metadata":{"id":"soTRG4WV7VPW"}},{"cell_type":"markdown","source":["Вторая методика решения нелинейных задач"],"metadata":{"id":"aGUX4BUiMZez"}},{"cell_type":"markdown","source":["*опрелелим* функцию близости как \"гауссову радиальную базисную функцию\" – **RBF**"],"metadata":{"id":"0X_YE83xMkh2"}},{"cell_type":"markdown","source":["Простейший подход к созданию ориениров заключается в **положении ориентира по мету каждого образца**. При таком подходе создается много измерений и тем самым растут шанты на то, что трансформированный набор данных будет линейно сепарабельным. "],"metadata":{"id":"A_nEhMr3N4gN"}},{"cell_type":"markdown","source":["Но **минус** заключается в том, что обучающий набор с m образцами и n признаками трансформируется в набор с m образцами и m признаками.\n","\n","m x n ---> m x m"],"metadata":{"id":"6Bt3f7dqOaRj"}},{"cell_type":"code","source":["rbf_kernel_svm_clf = Pipeline([\n","        (\"scaler\", StandardScaler()),\n","        (\"svm_clf\", SVC(kernel=\"rbf\", gamma=5, C=0.001))\n","    ])\n","rbf_kernel_svm_clf.fit(X, y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PzvQ3YB1MTPn","executionInfo":{"status":"ok","timestamp":1641470347715,"user_tz":-180,"elapsed":779,"user":{"displayName":"Mark Apiezon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyGsSipbrttT9pVeCINkKIDu1XY1NIVGNEPe6c=s64","userId":"11353121438293927929"}},"outputId":"bcadd7f3-1ae7-4f8d-b480-9a558c82178a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('scaler', StandardScaler()),\n","                ('svm_clf', SVC(C=0.001, gamma=5))])"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","source":["Класс SVC:\n","\n","1. kernel – ядро\n","2. gamma – увеличение --> сужение функции (сфера влияния каждого образца уменьшается)\n","3. C – увеличение --> сужение зазора"],"metadata":{"id":"0lNJRkdBQi6p"}},{"cell_type":"markdown","source":["## Гауссово ядро RBF"],"metadata":{"id":"0DXTSyYO7hMm"}},{"cell_type":"markdown","source":["# Регрессия SVM"],"metadata":{"id":"_ZvHGUIU6WG_"}},{"cell_type":"markdown","source":["LinearSVR"],"metadata":{"id":"3X6kwZoyYyLa"}},{"cell_type":"markdown","source":["Прием заключается в инвертировании цели"],"metadata":{"id":"stoFI99w7uCm"}},{"cell_type":"code","source":["from sklearn.svm import LinearSVR\n","\n","svm_reg = LinearSVR(epsilon=1.5, random_state=42)\n","svm_reg.fit(X, y)"],"metadata":{"id":"pemdnhKA7wPW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641472643716,"user_tz":-180,"elapsed":586,"user":{"displayName":"Mark Apiezon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyGsSipbrttT9pVeCINkKIDu1XY1NIVGNEPe6c=s64","userId":"11353121438293927929"}},"outputId":"bbabcba1-179d-430c-9fdd-59f6e12947b2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LinearSVR(epsilon=1.5, random_state=42)"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["from sklearn.svm import SVR\n","\n","svm_poly_reg = SVR(kernel=\"poly\", degree=2, C=100, epsilon=0.1, gamma=\"auto\")\n","svm_poly_reg.fit(X, y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"smUQztZIbF8_","executionInfo":{"status":"ok","timestamp":1641473141366,"user_tz":-180,"elapsed":350,"user":{"displayName":"Mark Apiezon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyGsSipbrttT9pVeCINkKIDu1XY1NIVGNEPe6c=s64","userId":"11353121438293927929"}},"outputId":"e2a609ef-1863-4b09-c63e-874709dcc300"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SVR(C=100, degree=2, gamma='auto', kernel='poly')"]},"metadata":{},"execution_count":46}]},{"cell_type":"markdown","source":["# Классы из sklearn для SVM"],"metadata":{"id":"g546O_3uTM2L"}},{"cell_type":"markdown","source":["### Классификация"],"metadata":{"id":"hDJodytCZp29"}},{"cell_type":"markdown","source":["**LinearSVC** – для линейных методов SVM\n","\n","*   loss=\"hinge\" – желатоельно\n","*   dual=False\n","*   C=10\n","\n","Нужно центрировать `StandardScaler`\n","\n","Можно добавить полиноминалные признаки классом `PolynominalFeatures`\n","\n","* degree=3 (example)\n","\n","1. PolynominalFeatures (не обязательно)\n","2. StandardScaler\n","3. LinearSVC\n","\n","Добавление малого количества полиноминальных признаков не сможет справиться с очень сложными наборами, а при высокой создает огромное количество признаков. Иногда применяют ядерный трюк, который поддерживается классом `SVC`\n","\n","---\n","\n","\n","**SVC** – поддерживает ядерный трюк. Может использоваться для линейной классификации\n","\n","* kernel = \"linear\",\"poly\",\"rbf\"\n","  * gamma(rbf) = 5\n","* degree=3\n","* coef0=1\n","* C=1\n","\n","\n","---\n","\n","\n","**SGDClassifier** – на основе ГС\n","\n","*   loss=\"hinge\"\n","*   alpha"],"metadata":{"id":"sIFgxEzQTW3j"}},{"cell_type":"markdown","source":["### Регрессия"],"metadata":{"id":"b0KHN0GhZtAZ"}},{"cell_type":"markdown","source":["**LinearSVR** –\n","* epsilon = 1.5\n","\n","\n","---\n","\n","\n","**SVR** – поддерживает ядерный трюк\n","* kernel=\"poly\"\n","* degree=2\n","* C=100\n","* epsilon=0.1\n","* gamma = \"auto\""],"metadata":{"id":"5XY4ceURZwah"}}]}